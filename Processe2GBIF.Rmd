---
title: "Process Data to GBIF format"
author: "Raphaël Nussbaumer <raphael.nussbaumer@arocha.org>"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---


## Introduction
This script reads the birdlasser files collected on the ground and produces the `events.csv` and `occurances.csv` files in Darwin format for the publication of the [Bird Survey Around Mida Creek](https://a-rocha-kenya.github.io/Bird-Survey-Around-Mida-Creek/) on [GBIF](doi).


```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(purrr)
library(lubridate)
library(leaflet)
library(sp)
library(rgdal)
library(RColorBrewer)
library(DT)
library(leaflet.extras)
library(geosphere)
library(imputeTS)
library(sf)
library(jsonlite)

project.root = 'C:/Users/rnussba1/ARK/Science - Documents/04 Geolocator/7-Output/Bird-Survey-Around-Mida-Creek/'
```

## Load surveys metadata

A *session* comprise around 90 *surveys* gathered during a month each of them covering a different *transects*. Sessions are repeated every month. A *survey* is a ~1 hours (non-stop) recording of all species encountered.

For each sessions (usualy 4 surveys performed from 6am to 10am), a birdlasser csv file with all the species recorded is exported by the observer and sent to me. All the files received are stored in `/birdlasser_files/` folder and additional information of each survey is recorded in the `metadata.xlsx` file:

* `filename`: Birdlasser file name containing the data of the survey and stored in `/birdlasser_files/`
* `observer`: Letter for each observer L (Kirao Lennox), J (Juma Badi), D (Daniel Kazungu), K (Kibwana Ali), S (Saddam Kailo) and M(Mohammed Ali)
* `sessionID`: Session identifier (monthly grouping of survey covering all the transects), `YYYYMM` with the month where most surveys were done. 
* `Date`: Date of the survey
* `start_time`: Time of start of the survey
* `end_time` : Time of the end of the survey
* `first_sighting`: DEPRECATED: before `unidentified` was used to specify the start and end time, we used this.
* `last_sighting`: DEPRECATED
* `protocol_ok`: whether the data are properly recorded (`TRUE` or `FALSE`)
* `gap_min`: duration of the survey where bird were not recorded (often because of rain) in `MM:HH`.
* `notes`: Additional notes with respect to the survey

Here, we read this file as table and add computed variable:

* `start_hour`: (start time rounded to the closer hour) so 6,7,8,9,10 or 11
* `duration`: (end-start-gaps) and create an survey 
* `surveyID` an unique identifier per survey 

```{r}
all_surveys <- read_excel(paste(project.root,"data/metadata.xlsx",sep="/"), sheet=2) %>% 
  filter(ifelse(is.na(protocol_ok), TRUE, FALSE)) %>% 
  mutate(
    filename = filename,
    date = force_tz(date,tzone = "Africa/Nairobi"),
    start_time = parse_time(format(start_time,'%H:%M')),
    #first_sighting = parse_time(format(first_sighting,'%H:%M')),
    #last_sighting = parse_time(format(last_sighting,'%H:%M')),
    end_time = parse_time(format(end_time,'%H:%M')),
    gap_min = ifelse( is.na(gap_min), 0, as.integer(format(gap_min,'%M'))),
    start_hour = parse_time(format(round(as.POSIXct(start_time, format="%H:%M:%S"), units="hours"),'%H:%M')),
    surveyID = paste( sessionID, format(date, "%Y%m%d"), str_replace(start_hour,':00:00','') , observer, sep = '_' ),
    notes = notes,
    observer = observer,
    .keep = "used"
    )
```

We replace the observer code (first letter) by the full name of the observer

```{r}
matchName <- function(x) {
  if (x=="L"){
    "Kirao Lennox"
  } else if(x=="J"){
    "Juma Badi"
  } else if(x=="D"){
    "Daniel Kazungu"
  } else if(x=="K"){
    "Kibwana Ali"
  } else if(x=="S"){
    "Saddam Kailo"
  } else if(x=="M"){
    "Mohammed Ali"
  }
}

all_surveys <- all_surveys %>% mutate(
  recordedBy =  unlist(map(str_extract_all(observer,''), ~str_c(unlist(map_chr(.x,matchName)), collapse = "|"))),
)
```

Here is extract (first 5 rows) of the dataset of surveys

```{r}
datatable(all_surveys %>% head(), filter = "top", extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = c('csv')), rownames = FALSE, class = "compact")
```

## Load Sightings data

Based on the metadata of each survey loaded in the previous section, we can now create the database including all sightings (i.e. individual observation) and associated survey information. 

```{r}
draw <- all_surveys %>%  
  pmap_dfr(function(...) {
  s <- tibble(...)
  s
  read_csv(paste(project.root,'/data/birdlasser_files/', s$filename,'.csv',sep=""),
           col_types = cols_only(
             `Species primary name` = col_character(),
             `BirdMAP ID` = col_double(),
             Date = col_character(),
             Time = col_time(format = ""),
             Latitude = col_double(),
             Longitude = col_double(),
             Notes = col_character()
             )
           ) %>% 
    mutate(Date = parse_date_time(Date,c("%Y-%m-%d", "%d/%m/%Y"), exact=TRUE, tz = "Africa/Nairobi" )) %>% # date are formated differently, this line allow to read both format
    filter(Date == s$date, s$start_time <= Time, s$end_time >= Time ) %>% # filter data for the survey
    mutate(
      specieName = `Species primary name`,
      specieID = `BirdMAP ID`,
      date = Date+Time,
      lat = Latitude,
      lng = Longitude,
      note = Notes,
      recordID = paste(s$surveyID,specieID,sep="_"),
      # From Survey information
      surveyID = s$surveyID,
      sessionID = s$sessionID,
      # filename = s$filename,
      recordedBy = s$recordedBy,
      #  start_hour = s$start_hour,
      #  duration = s$duration,
      #  start_time = s$start_time,
      #  end_time = s$end_time,
      #  gap_min = s$gap_min,
      #  notes_survey = s$notes,
      .keep = "none"
   ) %>% 
    arrange(date)
})


datatable(draw %>% head(), filter = "top", extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = c('csv')), rownames = FALSE, class = "compact")
```

## Surveys cleaning

In this section, we clean the surveys data from erronous location and species

```{r}
dCleaned <- draw
```

### Cleaning location

We remove and interpolate the wrong location of the individual sightings which were determined by visual checking (see map below
) 
```{r}
errorLocList = c(
  '202006_20200528_06_JD_0','202006_20200528_06_JD_545','202006_20200610_06_JD_0','202006_20200616_06_JD_0','202006_20200616_06_JD_517','202006_20200701_06_JD_0','202006_20200701_06_JD_989','202006_20200701_06_JD_784','202006_20200624_09_JD_797','202006_20200610_08_JD_0','202006_20200610_07_JD_0','202006_20200610_07_JD',
  '202007_20200713_06_JM_517','202007_20200721_07_JM_521','202007_20200713_06_JM_314',
  '202008_20200817_06_JM_0','202008_20200818_06_JM_0','202008_20200819_06_JM_989','202008_20200819_06_JM_0','202008_20200821_07_JM_551','202008_20200817_08_JM_989',
  '202010_20201105_06_JM_0','202010_20201108_07_JM_3834',
  '202012_20201215_06_JK_0','202012_20201212_07_JK_3024','202012_20201215_08_JK_0','202012_20201212_07_JK_859','202012_20201210_09_JK_580','202012_20201215_07_JK_0',
  '202101_20210111_08_JM_685','202101_20210113_06_JM_649','202101_20210119_07_JM_3834','202101_20210121_08_JM_144','202101_20210125_06_JM_321',
  '202103_20210309_09_SK_712','202103_20210310_09_SK_772','202103_20210325_07_JM_772','202103_20210315_06_JM_390','202103_20210315_07_JM_715','202103_20210315_07_JM_627','202103_20210319_06_JM_3024','202103_20210316_07_JM_422','202103_20210317_08_JM_385','202103_20210313_06_SK_387','202103_20210313_06_SK_712','202103_20210313_06_SK_654','202103_20210310_09_JM_772','202103_20210309_09_JM_712','202103_20210315_06_JM_723','202103_20210325_07_JM_3032','202103_20210315_06_JM_627','202103_20210315_06_JM_0','202103_20210313_06_JM_654','202103_20210313_06_JM_712','202103_20210313_06_JM_387',
  '202104_20210406_09_JM_3032','202104_20210407_09_JM_385','202104_20210406_08_JM_715','202104_20210417_08_JM_401','202104_20210417_07_JM_517','202104_20210417_09_JM_413','202104_20210416_09_JM_3032','202104_20210416_08_JM_756','202104_20210406_08_JM_493','202104_20210407_08_JM_656','202104_20210408_07_JM_76','202104_20210406_09_JM_517','202104_20210407_08_JM_682','202104_20210406_09_JM_0','202104_20210416_09_JM_387','202104_20210417_09_JM_517','202104_20210417_09_JM_413','202104_20210417_08_SK_723',
  '202105_20210522_06_JM_0','202105_20210521_08_JM_436','202105_20210510_07_SK_729','202105_20210513_06_JM_521','202105_20210513_06_JM_989','202104_20210413_09_JM_3834','202104_20210406_08_JM_0','202104_20210413_07_JM_412', '202105_20210515_09_JM_3974','202105_20210511_09_JM_390','202105_20210512_09_JM_736','202105_20210522_06_JM_400','202105_20210522_06_JM_0','202105_20210518_08_JM_144','202105_20210518_08_JM_740','202105_20210517_08_JM_989','202105_20210517_06_JM_0','202105_20210517_07_JM_0','202105_20210511_08_JM_712'
  )

dCleaned <- dCleaned %>% mutate(
     georeferenceVerificationStatus = ifelse(recordID %in% errorLocList, "corrected with linear interpolation by RN","verified visually by RN"),
     georeferenceRemarks = ifelse(recordID %in% errorLocList, paste0('Initial coordinate: ', lng, ', ',lat),'')
  )

dCleaned[dCleaned$recordID %in% errorLocList,]$lng=NA
dCleaned[dCleaned$recordID %in% errorLocList,]$lat=NA

for (s in unique(dCleaned$surveyID)){
  id = dCleaned$surveyID==s
  dCleaned[id,]$lat = na_interpolation(dCleaned[id,]$lat)
  dCleaned[id,]$lng = na_interpolation(dCleaned[id,]$lng)
}
  
```

Visualized on a map all sightings to identify the erronous location. Select specific session for ease of cleaning

```{r}

# all_surveys$sessionID %>% unique()

ds = dCleaned %>% filter(sessionID=='202008')

m <- leaflet(width = "100%") %>%
  addProviderTiles("MapBox", options = providerTileOptions(
    id = "mapbox.satellite",
    accessToken = 'pk.eyJ1IjoicmFmbnVzcyIsImEiOiIzMVE1dnc0In0.3FNMKIlQ_afYktqki-6m0g')) %>% 
  addFullscreenControl()

factpal <- colorFactor(brewer.pal(12, 'Paired'), as.factor(ds$surveyID))

for (s in unique(ds$surveyID)){
  m <- addPolylines(m, data=ds %>% 
                      filter(surveyID==s) %>% 
                      mutate(      
                        day = format(date,"%Y%m%d"),
                        label = paste0(
                         "<b>Date:</b> ", date,'<br>',
                         "<b>surveyID</b>: ", surveyID,'<br>'
                      )),
                    lng = ~lng, lat = ~lat , 
                    group = ~day, 
                    color=~factpal(surveyID), popup = ~label)
}

m <- addCircleMarkers(m, data = ds %>%
                  mutate(
                    day = format(date,"%Y%m%d"),
                    label = paste0(
                       "<b>recordID</b>: ", recordID,'<br>',
                       "<b>Species:</b> ", specieName,'<br>',
                       "<b>Date:</b> ", date, '<br>',
                       "<b>surveyID</b>: ", surveyID,'<br>'
                  )),
                lng = ~lng, lat = ~lat, popup = ~label,
                radius = ~ifelse(specieID==400, 10, 6),
                stroke = FALSE,
                fillOpacity = ~ifelse(specieID==400, 1, 0.8),
                color = ~factpal(surveyID),
                group = ~day)

m <- m %>% addLayersControl(
    overlayGroups =  format(ds$date,"%Y%m%d"),
    options = layersControlOptions(collapsed = FALSE)
  )

m
```

### Cleaning Species

The cleaning of the species is based on an external dataset where all species reported were manually checked (validated or flagged as error). Here, we load this spreasheet and apply the correction (remove or replace with equivalent speceID).

```{r}
species.list.validation <- read_xlsx(paste0(project.root, '/data/species_lists_validation.xlsx'), range = "A1:F288") %>% 
  mutate(`Equivalent specieID` = ifelse(is.na(`Equivalent specieID`) & grepl("Error",Status) ,0,`Equivalent specieID`))

dCleaned <- dCleaned %>% 
  right_join(species.list.validation, by="specieID") %>% 
  mutate(
    identificationVerificationStatus = Status,
    identificationRemarks = paste0(ifelse(is.na(Comment),'',Comment), ifelse(!is.na(Comment)&!is.na(`Equivalent specieID`),' | ',''), ifelse(is.na(`Equivalent specieID`),'',paste0('Original entry: ', specieName.x,' (',specieID,')'))),
  ) %>%
  mutate(specieID = ifelse(is.na(`Equivalent specieID`),specieID,`Equivalent specieID`)) %>% 
  select(-c('specieName.x','specieName.y','Comment','Equivalent specieID','Status','NumberObs'))
```

We add external information (specie name, family, etc...) based on the Species list from the [2019 Checklist of the Birds of Kenya 5th Edition](https://github.com/A-Rocha-Kenya/Birds-of-Kenya)

```{r}
species.list <- read_xlsx('C:/Users/rnussba1/Documents/GitHub/Birds-of-Kenya/Checklist of the Birds of Kenya 5th Edition (2019)/2019 Checklist of the Birds of Kenya 5th Edition (2019).xlsx', sheet = "main")

dCleaned <- dCleaned %>% left_join(species.list, by=c("specieID" = "ADU"))

# Check for no match
dCleaned %>% filter(is.na(family_english )) %>% .$specieID %>% unique()
```

```{r}
dsp = dCleaned %>% 
  group_by(specieID) %>% 
  summarise(
    common_name = first(common_name),
    scientific_name = first(scientific_name),
    family_english = first(family_english),
    NumberObs = n(),
    ) %>% 
  arrange(NumberObs)
  
datatable(dsp, filter = "top", extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = c('csv')), rownames = FALSE, class = "compact")
```



## Add location information to survey

As location information have to be added to the event data (i.e., survey), we add to each surveys (in `all_surveys`) the transect name and footprintWKT.

```{r}
f <- paste0(project.root,"/data/transects.geojson")
geojson <- fromJSON(f)
track = readOGR(f,require_geomType = "wkbLineString",verbose=F) %>% spTransform( CRS("+init=epsg:4326"))

mtrack <- matrix(unlist(lapply(coordinates(track), function(x) apply(x[[1]],2,mean))),nrow=2) 

dLineStr <- dCleaned %>%
  mutate(
    lat2=lat,
    lng2=lng,
  ) %>% 
  st_as_sf(coords = c("lng","lat")) %>%
  group_by(surveyID) %>% 
  summarize(
    mlat = mean(lat2),
    mlng = mean(lng2),
    transectName = geojson$features$properties$Name[unlist(map2(mlng,mlat,function(mlng,mlat) which.min((mlng-mtrack[1,])^2 + (mlat-mtrack[2,])^2 )))]
  ) %>% 
  st_cast("LINESTRING") %>% 
  mutate(footprintWKT=st_as_text(geometry))

all_surveys <- all_surveys %>% right_join(dLineStr,by = "surveyID")
```

Visualization of the transects

```{r}
factpal <- colorFactor(brewer.pal(12, 'Paired'), as.factor(dLineStr$transectName))

leaflet(width = "100%") %>%
  addProviderTiles("MapBox", options = providerTileOptions(
    id = "mapbox.satellite",
    accessToken = 'pk.eyJ1IjoicmFmbnVzcyIsImEiOiIzMVE1dnc0In0.3FNMKIlQ_afYktqki-6m0g')) %>% 
  addFullscreenControl() %>% 
  addPolylines(data=dLineStr, group = ~transectName, color=~factpal(transectName)) %>% 
  addPolylines(data=track, popup = geojson$features$properties$Name, color = ~factpal(geojson$features$properties$Name),opacity = 1,group = geojson$features$properties$Name) %>% 
  addLayersControl(
    overlayGroups =  dLineStr$transectName,
    options = layersControlOptions(collapsed = FALSE)
  )

```


## Export in Darwin format


### Export Event table
```{r}
events <- all_surveys %>% 
  transmute(
    type = "Event",
    language = "en",
    license = "http://creativecommons.org/publicdomain/zero/1.0/legalcode",
    rightsHolder = "A Rocha Kenya",
    ownerInstitutionCode = "ARK",
    eventID = surveyID,
    parentEventID = sessionID,
    samplingProtocol = 'Water Bird Count',
    sampleSizeValue = difftime(end_time,start_time, units="mins")-gap_min,
    sampleSizeUnit = "minutes",
    # samplingEffort = coverage,
    eventDate = format(date,"%Y-%m-%d"),
    eventTime = paste0(format(start_time,"%H:%M"),"/",format(end_time,"%H:%M")),
    eventRemarks = notes,
    # Locations
    # locationID = transectID,
    continent = "Africa",
    country = "Kenya",
    countryCode = "KE",
    # stateProvince =" ",
    county = "Kilifi",
    # municipality = if_else(site=='Sabaki', "Sabaki", "Mida"),
    locality = transectName,
    # locationRemarks = description,
    # decimalLatitude = latitude,
    # decimalLongitude = longitude,
    geodeticDatum ="WGS84",
    footprintWKT = footprintWKT,
    #georeferencedBy = "Raphaël Nussbaumer",
    #georeferencedDate = "03/06/2020",
    #georeferenceSources = "https://www.geonames.org/ | https://www.google.co.ke/maps/",
    #georeferenceVerificationStatus = "verified by curator",
    #georeferenceRemarks = "",
    dynamicProperties = paste0("{",
      'gap: "',gap_min,'", ',
      "}"
    ),
    )
```

### Export occurance table
```{r}
occurrences <- dCleaned %>% 
  transmute(
    # Occurrence
    occurrenceID = recordID,
    basisOfRecord = "HumanObservation",
    occurrenceRemarks = note,
    occurrenceStatus = "present",
    # Location
    decimalLatitude = lat,
    decimalLongitude = lng,
    georeferenceVerificationStatus = georeferenceVerificationStatus,
    georeferenceRemarks = georeferenceRemarks,
    # Taxon
    taxonID = `Clements--code`,
    taxonRank = `Clements--rank`,
    kingdom = "Animalia",
    phylum = "Chordata",
    class = "Aves",
    family = family_scientific,
    # scientificNameAuthorship = "",
    scientificName = scientific_name,
    vernacularName = common_name,
    identificationVerificationStatus = identificationVerificationStatus,
    identificationRemarks = identificationRemarks,
    # Others
    eventID = surveyID,
    # parentEventID = sessionID,
    recordedBy = recordedBy,
      )
```

## Write to Excel
```{r}
write.csv(events, file = paste(project.root,"data/events.csv",sep="/"),  na = "", row.names = FALSE, fileEncoding = "UTF-8")
write.csv(occurrences, file = paste(project.root,"data/occurrences.csv",sep="/"), na = "", row.names = FALSE, fileEncoding = "UTF-8")
```







